\chapter{稀疏复原问题的算法}\label{chap:srt03:algorithms}

\section{前言}
 
本章将对几种 常用的稀疏信号复原算法，如贪婪算法、有效集方法（如LARS算法）、块坐标下降、迭代阈值与近端法等进行总结。主要针对前面介绍的含噪稀疏复原问题，即最终不易处理的$ \ell_0 $范数最小化问题。
\begin{equation}\label{key}
(p_{0}^{\epsilon}):\qquad \min_{x}\Vert x\Vert_0\quad s.t.\quad\Vert y-Ax\Vert_2\leq \varepsilon
\end{equation}
与$ \ell_1 $范数松弛，也成为LASSO或基追踪
\begin{equation*}\label{key}
(p_{1}^{\epsilon}):\qquad \min_{x}\Vert x\Vert_1\quad s.t.\quad\Vert y-Ax\Vert_2^2\leq v
\end{equation*}
以及等价的拉格朗日形式
\begin{equation}\label{key}
(p_{1}^{\lambda}):\qquad \min_{x} \dfrac{1}{2}\Vert y-Ax\Vert_2^2 + \lambda \Vert x\Vert_1 \qquad
\end{equation}

其中$ x $为$ n $维未知稀疏信号，从统计学角度来说对应于线性回归中的稀疏向量，每一个系数$ x_i $表示第$ i $个输入或预测因子$ A_i $对输出$ y $的影响程度，$ y $为目标变量$ Y $的$ m $维观测向量。$ A $为$ m\times n $维设计矩阵，其第$ i $列为随机变量$ A_i $的$ m $维样本，即$ A $为$ m $个独立同分布的观测集合。


在讨论稀疏复原问题的特定算法之前，需要指出问题$(p_{1}^{\epsilon})  $和问题$ (p_{1}^{\lambda}) $可以利用一般的优化技术求解。然而在实际应用中，收敛速度可能比较慢，而且解通常是非稀疏的。

而且问题$ (p_{1}^{\lambda}) $可以转化为一个二次规划问题，从而可以应用一般的工具箱，如CVX对其进行求解。但该方法适用于小规模问题。一般的二次规划问题求解复杂度并不与问题规模成正比。因此，{\heiti 有必要挖掘稀疏复原问题的特定结构，研究求解问题$(p_{1}^{\epsilon})  $和问题$ (p_{1}^{\lambda}) $的特定方法，并将问题扩展到其他类型的目标函数与正则函数。}

\section{一元阈值是正交设计的最优方法}
在开始介绍求解上述问题的方法前，将先考虑正交设计矩阵的特殊情况。事实证明，当$\ell_0$ 与$\ell_1$范数优化问题分解为独立的一元问题时，其最优解可以通过非常简单的一元阈值过程得到。

$ n $维正交标准矩阵满足$ A^T A =AA^T=I$，由正交矩阵$ A $定义的线性变换具有一个良好的性质：保持向量的$ \ell_2 $范数不变，即：
$$  \Vert Ax \Vert_2^2 = (Ax)^T(Ax) =x^T(A^TA)x = x^Tx = \Vert x \Vert_2^2$$

对于$A^T$,具有同样的性质，因此可以得到
$$  \Vert y-Ax \Vert_2^2 = \Vert A^T( y-Ax) \Vert_2^2 = \Vert \hat{x}-x \Vert_2^2 = \sum_{i=1}^n (
\hat{x_i}-x_i)$$

其中，当A为正交阵时，$ \hat{x} = A^T y $对应于普通最小二乘解（OLS解），即：
\begin{equation}\label{key}
\hat{x} = \arg \min_x \: \Vert y-Ax\Vert^2
\end{equation}

接下来，将说明上述平方和损失函数如果极大简化$ \ell_0 $和$ \ell_1 $范数优化问题。


\section{求解$ \ell_0 $范数最小化的算法}
现在问题$ (p_{0}^{\epsilon}) $可以改写为：
\begin{equation}\label{key}
\min_{x}\Vert x\Vert_0\quad s.t. \quad  \sum_{i=1}^{n}(\hat{x}_i-x_i)^2\leq \varepsilon^2
\end{equation}

换句话说，我们正在寻找最稀疏解$ x^* $,即最小$ \ell_0 $范数解，该解与普通最小二乘解$ \hat{x}=A^Ty $的$ \ell_2 $范数距离不大于$ \epsilon $。通过选择选择$ \hat{x} $中k个最大（绝对值）坐标，并将其他坐标值设为0，可以很容易的构造这样的解。其中k为与$ \hat{x} $距离不大于$ \epsilon $的坐标最小数目，即使得解可行的坐标最小数目。该方法可以视为普通最小二乘法解$ \hat{x} $的一元硬阈值法。
\begin{equation}\label{key}
x_i^* = H(\hat{x}_i,\varepsilon) =
\left\{\begin{array}{r@{\:,\quad}l}
\hat{x}_i \quad &   |\hat{x}_i|\geq t(\varepsilon)\\
0         \quad &   |\hat{x}_i| <   t(\varepsilon)
\end{array} \right.
\end{equation}
其中，$ t(\varepsilon) $是阈值，小于$ {|\hat{x}_i|} $中第k个最大值，但大于第k+1个最大值。这里，将一元硬阈值运算表示为$ H(x,\varepsilon) $


\section{用于$ \ell_1 $范数最小化的算法}



